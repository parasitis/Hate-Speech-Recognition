# Hate-Speech-Recognition

The models are trained using SVM, NB, and RF machine learning methods following feature extraction. 
The K-fold cross-validation evaluation of the generated models is followed by the selection of the optimal detection model based on the validation outcomes. 
These activities lead to the creation of a detection model for offensive and hateful speech. 
Based on the findings of the model assessment technique discussion, the detection model is assessed and chosen. 

### About the dataset 
Dataset using Twitter data, it was used to research hate-speech detection. 
The text is classified as: hate-speech, offensive language, and neither. Due to the nature of the study, itâ€™s important to note that this dataset contains text that can be considered racist, sexist, homophobic, or generally offensive. 

### Pandas 
Pandas is an open-source library that is made mainly for working with relational or labeled data both easily and intuitively. It provides various data structures and operations for manipulating numerical data and time series. This library is built on top of the NumPy library. Pandas is fast and it has high performance & productivity for users. Pandas is an open-source, BSD-licensed Python library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language. Python with Pandas is used in a wide range of fields including academic and commercial domains including finance, economics, Statistics, analytics, etc. In this tutorial, we will learn the various features of Python Pandas and how to use them in practice. 

### Numpy 
NumPy stands for numeric python which is a python package for the computation and processing of the multidimensional and single dimensional array elements. It is an extension module of Python which is mostly written in C. It provides various functions which are capable of performing the numeric computations with a high speed. NumPy provides various powerful data structures, implementing multi-dimensional arrays and matrices. These data structures are used for the optimal computations regarding arrays and matrices. 

### NLTK 
The Natural Language Toolkit, or more commonly NLTK, is a suite of libraries and programs for symbolic and statistical natural language processing (NLP) for English written in the Python programming language.  NLTK has been used successfully as a teaching tool, as an individual study tool, and as a platform for prototyping and building research systems. NLTK (Natural Language Toolkit) Library is a suite that contains libraries and programs for statistical language processing. It is one of the most powerful NLP libraries, which contains packages to make machines understand human language and reply to it with an appropriate response. 

### CountVectorizer 
CountVectorizer is a great tool provided by the scikit-learn library in Python. It is used to transform a given text into a vector on the basis of the frequency (count) of each word that occurs in the entire CountVectorizer creates a matrix in which each unique word is represented by a column of the matrix, and each text sample from the document is a row in the matrix. The value of each cell is nothing but the count of the word in that particular text sample text. This is helpful when we have multiple such texts, and we wish to convert each word in each text into vectors (for use in further text analysis).

### Decision Tree Classifier 
Decision Tree is a Supervised learning technique that can be used for both classification and Regression problems, but mostly it is preferred for solving Classification problems. It is a tree-structured classifier, where internal nodes represent the features of a dataset, branches represent the decision rules and each leaf node represents the outcome. One of the most popular classification approaches is decision tree learning. It is highly efficient and has classification accuracy comparable to other learning methods. A decision tree is a tree that reflects the classification model that has been learned. It's an easy-to-understand decision tree classification paradigm. The method evaluates all feasible data split tests and chooses the one with the highest information gain.
